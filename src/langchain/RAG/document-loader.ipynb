{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d73f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can load documents from different souces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6116b10d",
   "metadata": {},
   "source": [
    "### Document Loaders\n",
    " - Recursive URL Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6f5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add -qU langchain-community beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f829ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "\n",
    "url_loader = RecursiveUrlLoader(\n",
    "    url=\"https://qwen.ai/blog?id=qwen3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2c29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = url_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835d02ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"background-color: #272822\">                                                                                                                   \n",
       " </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        var prodDomain = [</span><span style=\"background-color: #272822\">                                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'internal-qwenlm.alibaba-inc.com',</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'qwenlm.io',</span><span style=\"background-color: #272822\">                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'chat.qwenlm.ai',</span><span style=\"background-color: #272822\">                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'qwenlm.ai',</span><span style=\"background-color: #272822\">                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'qwen.ai',</span><span style=\"background-color: #272822\">                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'chat.qwen.ai',</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          'qwenchat.com'</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        ];</span><span style=\"background-color: #272822\">                                                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        var env = prodDomain.some((domain) =&gt; location.host === domain) ? 'prod' : 'pre';</span><span style=\"background-color: #272822\">                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        (function (w, d, s, q, i) {</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          var cookies = d.cookie.split(';').map(function (item) {</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            return item.trim().split('=');</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          });</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          function getCookie(name) {</span><span style=\"background-color: #272822\">                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            var item = cookies.find(function (item) {</span><span style=\"background-color: #272822\">                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">              return item[0] == name;</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            });</span><span style=\"background-color: #272822\">                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            return item ? encodeURIComponent(item[1]) : '';</span><span style=\"background-color: #272822\">                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          }</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          var aplusUrl =</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            env === 'pre'</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">              ? 'https://pre-chat.qwen.ai/scripts/stat.js'</span><span style=\"background-color: #272822\">                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">              : 'https://chat.qwen.ai/scripts/stat.js';</span><span style=\"background-color: #272822\">                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          w[q] = w[q] || [];</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          var f = d.getElementsByTagName(s)[0],</span><span style=\"background-color: #272822\">                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            j = d.createElement(s);</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          j.async = true;</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          j.id = 'beacon-aplus';</span><span style=\"background-color: #272822\">                                                                                  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          j.setAttribute('exparams', 'aplus&amp;sidx=aplusSidex&amp;ckx=aplusCkx');</span><span style=\"background-color: #272822\">                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          j.src = aplusUrl;</span><span style=\"background-color: #272822\">                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          f.parentNode.insertBefore(j, f);</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        })(window, document, 'script', 'aplus_queue');</span><span style=\"background-color: #272822\">                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    &lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"//g.alicdn.com/aes/??tracker/3.3.9/index.js,tracker-plugin-pv/3.0.6/index.js,tracker-plugin-event/3.0.0/inde</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">x.js,tracker-plugin-jserror/3.0.3/index.js,tracker-plugin-api/3.1.3/index.js,tracker-plugin-resourceError/3.0.4/i</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ndex.js,tracker-plugin-perf/3.1.0/index.js,tracker-plugin-eventTiming/3.0.0/index.js,tracker-plugin-autolog/3.0.1</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">3/index.js,tracker-plugin-blank/3.0.1/index.js,tracker-plugin-longtask/3.0.1/index.js\"&gt;&lt;/script&gt;&lt;script </span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nonce=3w4VMshMS_yq0an2STeBPg type=\"text/javascript\"&gt;</span><span style=\"background-color: #272822\">                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        window.aes = new AES({</span><span style=\"background-color: #272822\">                                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          pid: env === 'prod' ? 'qwen-ai' : 'pre-qwen-ai',</span><span style=\"background-color: #272822\">                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          env: env === 'prod' ? 'prod' : 'pre'</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        });</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        aes.use([</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          [</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          AESPluginAPI,</span><span style=\"background-color: #272822\">                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            {</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">              ignoreList: [</span><span style=\"background-color: #272822\">                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                function (url, obj) {</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                  return obj.status === 200;</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                }</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">              ]</span><span style=\"background-color: #272822\">                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            }</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          ],</span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          [AESPluginJSError],</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          AESPluginResourceError,</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          AESPluginPerf,</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          AESPluginEventTiming</span><span style=\"background-color: #272822\">                                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        ]);</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    &lt;/script&gt;&lt;div id=\"ice-container\"&gt;&lt;/div&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg&gt;!(function () {var a = </span><span style=\"background-color: #272822\">           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">window.__ICE_APP_CONTEXT__ || {};var b = </span><span style=\"background-color: #272822\">                                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{\"appData\":null,\"loaderData\":{\"layout\":{\"pageConfig\":{}},\"home\":{\"pageConfig\":{}}},\"routePath\":\"/home\",\"matchedId</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">s\":[\"layout\",\"home\"],\"documentOnly\":true,\"renderMode\":\"CSR\"};for (var k in a) {b[k] = </span><span style=\"background-color: #272822\">                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">a[k]}window.__ICE_APP_CONTEXT__=b;})();&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/80126a68.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/4591.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/79.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/896.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/4246.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/8394.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/3965.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9562.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/1349.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/2271.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9496.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/3154.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/8360.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/p_layout.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/b3cb5cc6.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9e22d361.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/5fb222f6.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/2766.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9986.js\"&gt;&lt;/script&gt;&lt;script nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/p_home-index.js\"&gt;&lt;/script&gt;&lt;script </span><span style=\"background-color: #272822\">                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/framework.js\"&gt;&lt;/script&gt;&lt;script </span><span style=\"background-color: #272822\">                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nonce=3w4VMshMS_yq0an2STeBPg src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/3164.js\"&gt;&lt;/script&gt;&lt;script </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nonce=3w4VMshMS_yq0an2STeBPg </span><span style=\"background-color: #272822\">                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/main.js\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   \n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \n",
       "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        var prodDomain = [\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'internal-qwenlm.alibaba-inc.com',\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'qwenlm.io',\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'chat.qwenlm.ai',\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'qwenlm.ai',\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'qwen.ai',\u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'chat.qwen.ai',\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          'qwenchat.com'\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        ];\u001b[0m\u001b[48;2;39;40;34m                                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        var env = prodDomain.some((domain) => location.host === domain) ? 'prod' : 'pre';\u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        (function (w, d, s, q, i) {\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          var cookies = d.cookie.split(';').map(function (item) {\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            return item.trim().split('=');\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          });\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          function getCookie(name) {\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            var item = cookies.find(function (item) {\u001b[0m\u001b[48;2;39;40;34m                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m              return item[0] == name;\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            });\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            return item ? encodeURIComponent(item[1]) : '';\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          }\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          var aplusUrl =\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            env === 'pre'\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m              ? 'https://pre-chat.qwen.ai/scripts/stat.js'\u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m              : 'https://chat.qwen.ai/scripts/stat.js';\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          w[q] = w[q] || [];\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          var f = d.getElementsByTagName(s)[0],\u001b[0m\u001b[48;2;39;40;34m                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            j = d.createElement(s);\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          j.async = true;\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          j.id = 'beacon-aplus';\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          j.setAttribute('exparams', 'aplus&sidx=aplusSidex&ckx=aplusCkx');\u001b[0m\u001b[48;2;39;40;34m                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          j.src = aplusUrl;\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          f.parentNode.insertBefore(j, f);\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        })(window, document, 'script', 'aplus_queue');\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    </script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"//g.alicdn.com/aes/??tracker/3.3.9/index.js,tracker-plugin-pv/3.0.6/index.js,tracker-plugin-event/3.0.0/inde\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mx.js,tracker-plugin-jserror/3.0.3/index.js,tracker-plugin-api/3.1.3/index.js,tracker-plugin-resourceError/3.0.4/i\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mndex.js,tracker-plugin-perf/3.1.0/index.js,tracker-plugin-eventTiming/3.0.0/index.js,tracker-plugin-autolog/3.0.1\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m3/index.js,tracker-plugin-blank/3.0.1/index.js,tracker-plugin-longtask/3.0.1/index.js\"></script><script \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnonce=3w4VMshMS_yq0an2STeBPg type=\"text/javascript\">\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        window.aes = new AES({\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          pid: env === 'prod' ? 'qwen-ai' : 'pre-qwen-ai',\u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          env: env === 'prod' ? 'prod' : 'pre'\u001b[0m\u001b[48;2;39;40;34m                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        });\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        aes.use([\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          [\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          AESPluginAPI,\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            {\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m              ignoreList: [\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                function (url, obj) {\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                  return obj.status === 200;\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                }\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m              ]\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            }\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          ],\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          [AESPluginJSError],\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          AESPluginResourceError,\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          AESPluginPerf,\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m          AESPluginEventTiming\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        ]);\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    </script><div id=\"ice-container\"></div><script nonce=3w4VMshMS_yq0an2STeBPg>!(function () {var a = \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwindow.__ICE_APP_CONTEXT__ || {};var b = \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\"appData\":null,\"loaderData\":{\"layout\":{\"pageConfig\":{}},\"home\":{\"pageConfig\":{}}},\"routePath\":\"/home\",\"matchedId\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ms\":[\"layout\",\"home\"],\"documentOnly\":true,\"renderMode\":\"CSR\"};for (var k in a) {b[k] = \u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ma[k]}window.__ICE_APP_CONTEXT__=b;})();</script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/80126a68.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/4591.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/79.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/896.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/4246.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/8394.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/3965.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9562.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/1349.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/2271.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9496.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/3154.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/8360.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/p_layout.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/b3cb5cc6.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9e22d361.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/5fb222f6.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/2766.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/9986.js\"></script><script nonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/p_home-index.js\"></script><script \u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/framework.js\"></script><script \u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnonce=3w4VMshMS_yq0an2STeBPg src=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/3164.js\"></script><script \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnonce=3w4VMshMS_yq0an2STeBPg \u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc=\"https://g.alicdn.com/qwenweb/qwen-ai-fe/0.0.47/js/main.js\"></script></body></html>\u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \n",
       "\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e2552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce89bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_loader = RecursiveUrlLoader(\n",
    "    url=\"https://qwen.ai/blog?id=qwen3\",\n",
    "    extractor=bs4_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48bb93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = url_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ebc7373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qwen'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d9d897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30f772ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fc-641458a3f46f46f49b1c0dc5c128808a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getenv(\"FIRECRAWL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e9a7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
    "\n",
    "data = FireCrawlLoader(url=\"https://qwen.ai/blog?id=qwen3\", api_key=os.getenv(\"FIRECRAWL_API_KEY\"), mode=\"scrape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8828daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55d720de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> <a href=\"https://img.alicdn.com/imgextra/i4/O1CN01a6pmNi24dfWQwmMp3_!!6000000007414-2-tps-270-90.png\" target=\"_blank\">logo</a>                                                                                                                    \n",
       "\n",
       "Qwen Chat                                                                                                          \n",
       "\n",
       "Research                                                                                                           \n",
       "\n",
       "API Platform                                                                                                       \n",
       "\n",
       "EN                                                                                                                 \n",
       "\n",
       "DownloadTry Qwen Chat                                                                                              \n",
       "\n",
       "Qwen3: Think Deeper, Act Faster                                                                                    \n",
       "\n",
       "2025/04/28  48 minute  9682 words  QwenTeamTranslations:                                              \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-banner.png\" target=\"_blank\">qwen3-banner.png</a>                                                                                                                    \n",
       "\n",
       "QWEN CHAT                                                                                                          \n",
       "\n",
       "GitHub                                                                                                             \n",
       "\n",
       "Hugging Face                                                                                                       \n",
       "\n",
       "ModelScope                                                                                                         \n",
       "\n",
       "Kaggle                                                                                                             \n",
       "\n",
       "DEMO                                                                                                               \n",
       "\n",
       "DISCORD                                                                                                            \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Introduction</span>                                                                                                       \n",
       "\n",
       "Today, we are excited to announce the release of <span style=\"font-weight: bold\">Qwen3</span>, the latest addition to the Qwen family of large language   \n",
       "models. Our flagship model, <span style=\"font-weight: bold\">Qwen3-235B-A22B</span>, achieves competitive results in benchmark evaluations of coding, math,\n",
       "general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and   \n",
       "Gemini-2.5-Pro. Additionally, the small MoE model, <span style=\"font-weight: bold\">Qwen3-30B-A3B</span>, outcompetes QwQ-32B with 10 times of activated   \n",
       "parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.                 \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-235a22.jpg\" target=\"_blank\">qwen3-235a22.jpg</a>                                                                                                                    \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-30a3.jpg\" target=\"_blank\">qwen3-30a3.jpg</a>                                                                                                                    \n",
       "\n",
       "We are open-weighting two MoE models: <span style=\"font-weight: bold\">Qwen3-235B-A22B</span>, a large model with 235 billion total parameters and 22      \n",
       "billion activated parameters, and <span style=\"font-weight: bold\">Qwen3-30B-A3B</span>, a smaller MoE model with 30 billion total parameters and 3 billion\n",
       "activated parameters. Additionally, six dense models are also open-weighted, including <span style=\"font-weight: bold\">Qwen3-32B</span>, <span style=\"font-weight: bold\">Qwen3-14B</span>,       \n",
       "<span style=\"font-weight: bold\">Qwen3-8B</span>, <span style=\"font-weight: bold\">Qwen3-4B</span>, <span style=\"font-weight: bold\">Qwen3-1.7B</span>, and <span style=\"font-weight: bold\">Qwen3-0.6B</span>, under Apache 2.0 license.                                          \n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">                                                                   </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Models</span><span style=\"font-weight: bold\">     </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Layers</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Heads (Q / KV)</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Tie Embedding</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Context Length</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">  </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-0.6B <span style=\"color: #008080; text-decoration-color: #008080\"> </span>28     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>16 / 8         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Yes           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>32K           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-1.7B <span style=\"color: #008080; text-decoration-color: #008080\"> </span>28     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>16 / 8         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Yes           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>32K           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-4B   <span style=\"color: #008080; text-decoration-color: #008080\"> </span>36     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>32 / 8         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Yes           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>32K           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-8B   <span style=\"color: #008080; text-decoration-color: #008080\"> </span>36     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>32 / 8         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>No            <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128K          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-14B  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>40     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>40 / 8         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>No            <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128K          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-32B  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>64     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>64 / 8         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>No            <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128K          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">                                                                   </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">                                                                                        </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Models</span><span style=\"font-weight: bold\">          </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Layers</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Heads (Q / KV)</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"># Experts (Total / Activated)</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Context Length</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">  </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-30B-A3B   <span style=\"color: #008080; text-decoration-color: #008080\"> </span>48     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>32 / 4         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128 / 8                       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128K          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Qwen3-235B-A22B <span style=\"color: #008080; text-decoration-color: #008080\"> </span>94     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>64 / 4         <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128 / 8                       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>128K          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">                                                                                        </span>\n",
       "\n",
       "The post-trained models, such as <span style=\"font-weight: bold\">Qwen3-30B-A3B</span>, along with their pre-trained counterparts (e.g.,                   \n",
       "<span style=\"font-weight: bold\">Qwen3-30B-A3B-Base</span>), are now available on platforms like <span style=\"font-weight: bold\">Hugging Face</span>, <span style=\"font-weight: bold\">ModelScope</span>, and <span style=\"font-weight: bold\">Kaggle</span>. For deployment, we  \n",
       "recommend using frameworks like <span style=\"font-weight: bold\">SGLang</span> and <span style=\"font-weight: bold\">vLLM</span>. For local usage, tools such as <span style=\"font-weight: bold\">Ollama</span>, <span style=\"font-weight: bold\">LMStudio</span>, <span style=\"font-weight: bold\">MLX</span>, <span style=\"font-weight: bold\">llama.cpp</span>,  \n",
       "and <span style=\"font-weight: bold\">KTransformers</span> are highly recommended. These options ensure that users can easily integrate Qwen3 into their    \n",
       "workflows, whether in research, development, or production environments.                                           \n",
       "\n",
       "We believe that the release and open-sourcing of Qwen3 will significantly advance the research and development of  \n",
       "large foundation models. Our goal is to empower researchers, developers, and organizations around the world to     \n",
       "build innovative solutions using these cutting-edge models.                                                        \n",
       "\n",
       "Feel free to try Qwen3 out in Qwen Chat Web ( <a href=\"https://chat.qwen.ai/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">chat.qwen.ai</span></a>) and mobile APP!                                        \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Key Features</span>                                                                                                       \n",
       "\n",
       "<span style=\"font-weight: bold\">Hybrid Thinking Modes</span>                                                                                              \n",
       "\n",
       "Qwen3 models introduce a hybrid approach to problem-solving. They support two modes:                               \n",
       "\n",
       "Thinking Mode: In this mode, the model takes time to reason step by step before delivering the final answer. This  \n",
       "is ideal for complex problems that require deeper thought.                                                         \n",
       "\n",
       "Non-Thinking Mode: Here, the model provides quick, near-instant responses, suitable for simpler questions where    \n",
       "speed is more important than depth.                                                                                \n",
       "\n",
       "This flexibility allows users to control how much \"thinking\" the model performs based on the task at hand. For     \n",
       "example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without\n",
       "delay. Crucially, the integration of these two modes greatly enhances the model's ability to implement stable and  \n",
       "efficient thinking budget control. As demonstrated above, Qwen3 exhibits scalable and smooth performance           \n",
       "improvements that are directly correlated with the computational reasoning budget allocated. This design enables   \n",
       "users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost          \n",
       "efficiency and inference quality.                                                                                  \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/thinking_budget.png\" target=\"_blank\">thinking_budget.png</a>                                                                                                                    \n",
       "\n",
       "<span style=\"font-weight: bold\">Multilingual Support</span>                                                                                               \n",
       "\n",
       "Qwen3 models are supporting <span style=\"font-weight: bold\">119 languages and dialects</span>. This extensive multilingual capability opens up new        \n",
       "possibilities for international applications, enabling users worldwide to benefit from the power of these models.  \n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">                                                                                                                   </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Language Family</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080\">Languages &amp; Dialects</span><span style=\"font-weight: bold\">                                                                            </span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">  </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Indo-European   <span style=\"color: #008080; text-decoration-color: #008080\"> </span>English, French, Portuguese, German, Romanian, Swedish, Danish, Bulgarian, Russian, Czech,      <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Greek, Ukrainian, Spanish, Dutch, Slovak, Croatian, Polish, Lithuanian, Norwegian Bokml,       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Norwegian Nynorsk, Persian, Slovenian, Gujarati, Latvian, Italian, Occitan, Nepali, Marathi,    <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Belarusian, Serbian, Luxembourgish, Venetian, Assamese, Welsh, Silesian, Asturian,              <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Chhattisgarhi, Awadhi, Maithili, Bhojpuri, Sindhi, Irish, Faroese, Hindi, Punjabi, Bengali,     <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Oriya, Tajik, Eastern Yiddish, Lombard, Ligurian, Sicilian, Friulian, Sardinian, Galician,      <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Catalan, Icelandic, Tosk Albanian, Limburgish, Dari, Afrikaans, Macedonian, Sinhala, Urdu,      <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Magahi, Bosnian, Armenian                                                                       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Sino-Tibetan    <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Chinese (Simplified Chinese, Traditional Chinese, Cantonese), Burmese                           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Afro-Asiatic    <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Arabic (Standard, Najdi, Levantine, Egyptian, Moroccan, Mesopotamian, Ta'izzi-Adeni, Tunisian), <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Hebrew, Maltese                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Austronesian    <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Indonesian, Malay, Tagalog, Cebuano, Javanese, Sundanese, Minangkabau, Balinese, Banjar,        <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>                <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Pangasinan, Iloko, Waray (Philippines)                                                          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Dravidian       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Tamil, Telugu, Kannada, Malayalam                                                               <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Turkic          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Turkish, North Azerbaijani, Northern Uzbek, Kazakh, Bashkir, Tatar                              <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Tai-Kadai       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Thai, Lao                                                                                       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Uralic          <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Finnish, Estonian, Hungarian                                                                    <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Austroasiatic   <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Vietnamese, Khmer                                                                               <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span>Other           <span style=\"color: #008080; text-decoration-color: #008080\"> </span>Japanese, Korean, Georgian, Basque, Haitian, Papiamento, Kabuverdianu, Tok Pisin, Swahili       <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">                                                                                                                   </span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Improved Agentic Capabilities</span>                                                                                      \n",
       "\n",
       "We have optimized the Qwen3 models for coding and agentic capabilities, and also we have strengthened the support  \n",
       "of MCP as well. Below we provide examples to show how Qwen3 thinks and interacts with the environment.             \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Pre-training</span>                                                                                                       \n",
       "\n",
       "In terms of pretraining, the dataset for Qwen3 has been significantly expanded compared to Qwen2.5. While Qwen2.5  \n",
       "was pre-trained on 18 trillion tokens, Qwen3 uses nearly twice that amount, with approximately 36 trillion tokens  \n",
       "covering 119 languages and dialects. To build this large dataset, we collected data not only from the web but also \n",
       "from PDF-like documents. We used Qwen2.5-VL to extract text from these documents and Qwen2.5 to improve the quality\n",
       "of the extracted content. To increase the amount of math and code data, we used Qwen2.5-Math and Qwen2.5-Coder to  \n",
       "generate synthetic data. This includes textbooks, question-answer pairs, and code snippets.                        \n",
       "\n",
       "The pre-training process consists of three stages. In the first stage (S1), the model was pretrained on over 30    \n",
       "trillion tokens with a context length of 4K tokens. This stage provided the model with basic language skills and   \n",
       "general knowledge. In the second stage (S2), we improved the dataset by increasing the proportion of               \n",
       "knowledge-intensive data, such as STEM, coding, and reasoning tasks. The model was then pretrained on an additional\n",
       "5 trillion tokens. In the final stage, we used high-quality long-context data to extend the context length to 32K  \n",
       "tokens. This ensures the model can handle longer inputs effectively.                                               \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-base.jpg\" target=\"_blank\">qwen3-base.jpg</a>                                                                                                                    \n",
       "\n",
       "Due to advancements in model architecture, increase in training data, and more effective training methods, the     \n",
       "overall performance of Qwen3 dense base models matches that of Qwen2.5 base models with more parameters. For       \n",
       "instance, Qwen3-1.7B/4B/8B/14B/32B-Base performs as well as Qwen2.5-3B/7B/14B/32B/72B-Base, respectively. Notably, \n",
       "in areas like STEM, coding, and reasoning, Qwen3 dense base models even outperform larger Qwen2.5 models. For      \n",
       "Qwen3-MoE base models, they achieve similar performance to Qwen2.5 dense base models while using only 10% of the   \n",
       "active parameters. This results in significant savings in both training and inference costs.                       \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Post-training</span>                                                                                                      \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/post-training.png\" target=\"_blank\">post-training.png</a>                                                                                                                    \n",
       "\n",
       "To develop the hybrid model capable of both step-by-step reasoning and rapid responses, we implemented a four-stage\n",
       "training pipeline. This pipeline includes: (1) long chain-of-thought (CoT) cold start, (2) reasoning-based         \n",
       "reinforcement learning (RL), (3) thinking mode fusion, and (4) general RL.                                         \n",
       "\n",
       "In the first stage, we fine-tuned the models using diverse long CoT data, covering various tasks and domains such  \n",
       "as mathematics, coding, logical reasoning, and STEM problems. This process aimed to equip the model with           \n",
       "fundamental reasoning abilities. The second stage focused on scaling up computational resources for RL, utilizing  \n",
       "rule-based rewards to enhance the model's exploration and exploitation capabilities.                               \n",
       "\n",
       "In the third stage, we integrated non-thinking capabilities into the thinking model by fine-tuning it on a         \n",
       "combination of long CoT data and commonly used instruction-tuning data. This data was generated by the enhanced    \n",
       "thinking model from the second stage, ensuring a seamless blend of reasoning and quick response capabilities.      \n",
       "Finally, in the fourth stage, we applied RL across more than 20 general-domain tasks to further strengthen the     \n",
       "models general capabilities and correct undesired behaviors. These tasks included instruction following, format   \n",
       "following, and agent capabilities, etc.                                                                            \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Develop with Qwen3</span>                                                                                                 \n",
       "\n",
       "Below is a simple guide for you to use Qwen3 on different frameworks. First of all, we provide an standard example \n",
       "of using Qwen3-30B-A3B in Hugging Face transformers:                                                               \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "99                                                                                                                 \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "7                                                                                                                  \n",
       "\n",
       "8                                                                                                                  \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "10                                                                                                                 \n",
       "\n",
       "11                                                                                                                 \n",
       "\n",
       "12                                                                                                                 \n",
       "\n",
       "13                                                                                                                 \n",
       "\n",
       "14                                                                                                                 \n",
       "\n",
       "15                                                                                                                 \n",
       "\n",
       "16                                                                                                                 \n",
       "\n",
       "17                                                                                                                 \n",
       "\n",
       "18                                                                                                                 \n",
       "\n",
       "19                                                                                                                 \n",
       "\n",
       "20                                                                                                                 \n",
       "\n",
       "21                                                                                                                 \n",
       "\n",
       "22                                                                                                                 \n",
       "\n",
       "23                                                                                                                 \n",
       "\n",
       "24                                                                                                                 \n",
       "\n",
       "25                                                                                                                 \n",
       "\n",
       "26                                                                                                                 \n",
       "\n",
       "27                                                                                                                 \n",
       "\n",
       "28                                                                                                                 \n",
       "\n",
       "29                                                                                                                 \n",
       "\n",
       "30                                                                                                                 \n",
       "\n",
       "31                                                                                                                 \n",
       "\n",
       "32                                                                                                                 \n",
       "\n",
       "33                                                                                                                 \n",
       "\n",
       "34                                                                                                                 \n",
       "\n",
       "35                                                                                                                 \n",
       "\n",
       "36                                                                                                                 \n",
       "\n",
       "37                                                                                                                 \n",
       "\n",
       "38                                                                                                                 \n",
       "\n",
       "39                                                                                                                 \n",
       "\n",
       "40                                                                                                                 \n",
       "\n",
       "41                                                                                                                 \n",
       "\n",
       "42                                                                                                                 \n",
       "\n",
       "43                                                                                                                 \n",
       "\n",
       "44                                                                                                                 \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "from modelscope import AutoModelForCausalLM, AutoTokenizer                                                         \n",
       "\n",
       "model_name = \"Qwen/Qwen3-30B-A3B\"                                                                                  \n",
       "\n",
       "# load the tokenizer and the model                                                                                 \n",
       "\n",
       "tokenizer = AutoTokenizer.from_pretrained(model_name)                                                              \n",
       "\n",
       "model = AutoModelForCausalLM.from_pretrained(                                                                      \n",
       "\n",
       "model_name,                                                                                                        \n",
       "\n",
       "torch_dtype=\"auto\",                                                                                                \n",
       "\n",
       "device_map=\"auto\"                                                                                                  \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "# prepare the model input                                                                                          \n",
       "\n",
       "prompt = \"Give me a short introduction to large language model.\"                                                   \n",
       "\n",
       "messages = [                                                                                                       \n",
       "                                                                                                                   \n",
       "{\"role\": \"user\", \"content\": prompt}                                                                                \n",
       "                                                                                                                   \n",
       "]                                                                                                                  \n",
       "\n",
       "text = tokenizer.apply_chat_template(                                                                              \n",
       "\n",
       "messages,                                                                                                          \n",
       "\n",
       "tokenize=False,                                                                                                    \n",
       "\n",
       "add_generation_prompt=True,                                                                                        \n",
       "\n",
       "enable_thinking=True# Switch between thinking and non-thinking modes. Default is True.                             \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)                                             \n",
       "\n",
       "# conduct text completion                                                                                          \n",
       "\n",
       "generated_ids = model.generate(                                                                                    \n",
       "\n",
       "**model_inputs,                                                                                                    \n",
       "\n",
       "max_new_tokens=32768                                                                                               \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()                                            \n",
       "\n",
       "# parsing thinking content                                                                                         \n",
       "\n",
       "try:                                                                                                               \n",
       "\n",
       "\n",
       "# rindex finding 151668 ()                                                                                         \n",
       "\n",
       "index = len(output_ids) - output_ids[::-1].index(151668)                                                           \n",
       "\n",
       "except ValueError:                                                                                                 \n",
       "\n",
       "index = 0                                                                                                          \n",
       "\n",
       "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")                      \n",
       "\n",
       "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")                               \n",
       "\n",
       "print(\"thinking content:\", thinking_content)                                                                       \n",
       "\n",
       "print(\"content:\", content)                                                                                         \n",
       "\n",
       "To disable thinking, you just need to make changes to the argument <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">enable_thinking</span> like the following:             \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "text = tokenizer.apply_chat_template(                                                                              \n",
       "\n",
       "messages,                                                                                                          \n",
       "\n",
       "tokenize=False,                                                                                                    \n",
       "\n",
       "add_generation_prompt=True,                                                                                        \n",
       "\n",
       "enable_thinking=False# True is the default value for enable_thinking.                                              \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "For deployment, you can use <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">sglang&gt;=0.4.6.post1</span> or <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">vllm&gt;=0.8.4</span> to create an OpenAI-compatible API endpoint:        \n",
       "\n",
       "SGLang:                                                                                                            \n",
       "\n",
       "shell                                                                                                              \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3                            \n",
       "\n",
       "vLLM:                                                                                                              \n",
       "\n",
       "shell                                                                                                              \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1                                    \n",
       "\n",
       "If you use it for local development, you can use ollama by running a simple command <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">ollama run qwen3:30b-a3b</span> to    \n",
       "play with the model, or you can use LMStudio or llama.cpp and ktransformers to build locally.                      \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Advanced Usages</span>                                                                                                    \n",
       "\n",
       "We provide a soft switch mechanism that allows users to dynamically control the model's behavior when              \n",
       "enable_thinking=True. Specifically, you can add /think and /no_think to user prompts or system messages to switch  \n",
       "the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn       \n",
       "conversations.                                                                                                     \n",
       "\n",
       "Here is an example of a multi-turn conversation:                                                                   \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "99                                                                                                                 \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "7                                                                                                                  \n",
       "\n",
       "8                                                                                                                  \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "10                                                                                                                 \n",
       "\n",
       "11                                                                                                                 \n",
       "\n",
       "12                                                                                                                 \n",
       "\n",
       "13                                                                                                                 \n",
       "\n",
       "14                                                                                                                 \n",
       "\n",
       "15                                                                                                                 \n",
       "\n",
       "16                                                                                                                 \n",
       "\n",
       "17                                                                                                                 \n",
       "\n",
       "18                                                                                                                 \n",
       "\n",
       "19                                                                                                                 \n",
       "\n",
       "20                                                                                                                 \n",
       "\n",
       "21                                                                                                                 \n",
       "\n",
       "22                                                                                                                 \n",
       "\n",
       "23                                                                                                                 \n",
       "\n",
       "24                                                                                                                 \n",
       "\n",
       "25                                                                                                                 \n",
       "\n",
       "26                                                                                                                 \n",
       "\n",
       "27                                                                                                                 \n",
       "\n",
       "28                                                                                                                 \n",
       "\n",
       "29                                                                                                                 \n",
       "\n",
       "30                                                                                                                 \n",
       "\n",
       "31                                                                                                                 \n",
       "\n",
       "32                                                                                                                 \n",
       "\n",
       "33                                                                                                                 \n",
       "\n",
       "34                                                                                                                 \n",
       "\n",
       "35                                                                                                                 \n",
       "\n",
       "36                                                                                                                 \n",
       "\n",
       "37                                                                                                                 \n",
       "\n",
       "38                                                                                                                 \n",
       "\n",
       "39                                                                                                                 \n",
       "\n",
       "40                                                                                                                 \n",
       "\n",
       "41                                                                                                                 \n",
       "\n",
       "42                                                                                                                 \n",
       "\n",
       "43                                                                                                                 \n",
       "\n",
       "44                                                                                                                 \n",
       "\n",
       "45                                                                                                                 \n",
       "\n",
       "46                                                                                                                 \n",
       "\n",
       "47                                                                                                                 \n",
       "\n",
       "48                                                                                                                 \n",
       "\n",
       "49                                                                                                                 \n",
       "\n",
       "50                                                                                                                 \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "from transformers import AutoModelForCausalLM, AutoTokenizer                                                       \n",
       "\n",
       "classQwenChatbot:                                                                                                  \n",
       "\n",
       "def__init__(self, model_name=\"Qwen/Qwen3-30B-A3B\"):                                                                \n",
       "\n",
       "self.tokenizer = AutoTokenizer.from_pretrained(model_name)                                                         \n",
       "\n",
       "self.model = AutoModelForCausalLM.from_pretrained(model_name)                                                      \n",
       "\n",
       "self.history = []                                                                                                  \n",
       "\n",
       "defgenerate_response(self, user_input):                                                                            \n",
       "\n",
       "messages = self.history + [{\"role\": \"user\", \"content\": user_input}]                                                \n",
       "\n",
       "text = self.tokenizer.apply_chat_template(                                                                         \n",
       "\n",
       "messages,                                                                                                          \n",
       "\n",
       "tokenize=False,                                                                                                    \n",
       "\n",
       "add_generation_prompt=True                                                                                         \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "inputs = self.tokenizer(text, return_tensors=\"pt\")                                                                 \n",
       "\n",
       "response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()          \n",
       "\n",
       "response = self.tokenizer.decode(response_ids, skip_special_tokens=True)                                           \n",
       "\n",
       "# Update history                                                                                                   \n",
       "\n",
       "self.history.append({\"role\": \"user\", \"content\": user_input})                                                       \n",
       "\n",
       "self.history.append({\"role\": \"assistant\", \"content\": response})                                                    \n",
       "\n",
       "return response                                                                                                    \n",
       "\n",
       "# Example Usage                                                                                                    \n",
       "\n",
       "if __name__ == \"__main__\":                                                                                         \n",
       "\n",
       "chatbot = QwenChatbot()                                                                                            \n",
       "\n",
       "# First input (without /think or /no_think tags, thinking mode is enabled by default)                              \n",
       "\n",
       "user_input_1 = \"How many r's in strawberries?\"                                                                     \n",
       "\n",
       "print(f\"User: {user_input_1}\")                                                                                     \n",
       "\n",
       "response_1 = chatbot.generate_response(user_input_1)                                                               \n",
       "\n",
       "print(f\"Bot: {response_1}\")                                                                                        \n",
       "\n",
       "print(\"----------------------\")                                                                                    \n",
       "\n",
       "# Second input with /no_think                                                                                      \n",
       "\n",
       "user_input_2 = \"Then, how many r's in blueberries? /no_think\"                                                      \n",
       "\n",
       "print(f\"User: {user_input_2}\")                                                                                     \n",
       "\n",
       "response_2 = chatbot.generate_response(user_input_2)                                                               \n",
       "\n",
       "print(f\"Bot: {response_2}\")                                                                                        \n",
       "\n",
       "print(\"----------------------\")                                                                                    \n",
       "\n",
       "# Third input with /think                                                                                          \n",
       "\n",
       "user_input_3 = \"Really? /think\"                                                                                    \n",
       "\n",
       "print(f\"User: {user_input_3}\")                                                                                     \n",
       "\n",
       "response_3 = chatbot.generate_response(user_input_3)                                                               \n",
       "\n",
       "print(f\"Bot: {response_3}\")                                                                                        \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Agentic Usages</span>                                                                                                     \n",
       "\n",
       "Qwen3 excels in tool calling capabilities. We recommend using <a href=\"https://github.com/QwenLM/Qwen-Agent\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Qwen-Agent</span></a> to make the best use of agentic ability of\n",
       "Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding \n",
       "complexity.                                                                                                        \n",
       "\n",
       "To define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or   \n",
       "integrate other tools by yourself.                                                                                 \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "99                                                                                                                 \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "7                                                                                                                  \n",
       "\n",
       "8                                                                                                                  \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "10                                                                                                                 \n",
       "\n",
       "11                                                                                                                 \n",
       "\n",
       "12                                                                                                                 \n",
       "\n",
       "13                                                                                                                 \n",
       "\n",
       "14                                                                                                                 \n",
       "\n",
       "15                                                                                                                 \n",
       "\n",
       "16                                                                                                                 \n",
       "\n",
       "17                                                                                                                 \n",
       "\n",
       "18                                                                                                                 \n",
       "\n",
       "19                                                                                                                 \n",
       "\n",
       "20                                                                                                                 \n",
       "\n",
       "21                                                                                                                 \n",
       "\n",
       "22                                                                                                                 \n",
       "\n",
       "23                                                                                                                 \n",
       "\n",
       "24                                                                                                                 \n",
       "\n",
       "25                                                                                                                 \n",
       "\n",
       "26                                                                                                                 \n",
       "\n",
       "27                                                                                                                 \n",
       "\n",
       "28                                                                                                                 \n",
       "\n",
       "29                                                                                                                 \n",
       "\n",
       "30                                                                                                                 \n",
       "\n",
       "31                                                                                                                 \n",
       "\n",
       "32                                                                                                                 \n",
       "\n",
       "33                                                                                                                 \n",
       "\n",
       "34                                                                                                                 \n",
       "\n",
       "35                                                                                                                 \n",
       "\n",
       "36                                                                                                                 \n",
       "\n",
       "37                                                                                                                 \n",
       "\n",
       "38                                                                                                                 \n",
       "\n",
       "39                                                                                                                 \n",
       "\n",
       "40                                                                                                                 \n",
       "\n",
       "41                                                                                                                 \n",
       "\n",
       "42                                                                                                                 \n",
       "\n",
       "43                                                                                                                 \n",
       "\n",
       "44                                                                                                                 \n",
       "\n",
       "45                                                                                                                 \n",
       "\n",
       "46                                                                                                                 \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "from qwen_agent.agents import Assistant                                                                            \n",
       "\n",
       "# Define LLM                                                                                                       \n",
       "\n",
       "llm_cfg = {                                                                                                        \n",
       "\n",
       "'model': 'Qwen3-30B-A3B',                                                                                          \n",
       "\n",
       "# Use the endpoint provided by Alibaba Model Studio:                                                               \n",
       "\n",
       "# 'model_type': 'qwen_dashscope',                                                                                  \n",
       "\n",
       "# 'api_key': os.getenv('DASHSCOPE_API_KEY'),                                                                       \n",
       "\n",
       "# Use a custom endpoint compatible with OpenAI API:                                                                \n",
       "\n",
       "'model_server': 'http://localhost:8000/v1', # api_base                                                             \n",
       "\n",
       "'api_key': 'EMPTY',                                                                                                \n",
       "\n",
       "# Other parameters:                                                                                                \n",
       "\n",
       "# 'generate_cfg': {                                                                                                \n",
       "\n",
       "\n",
       "\n",
       "# # Add: When the response content is `this is the thoughtthis is the answer;                                      \n",
       "\n",
       "# # Do not add: When the response has been separated by reasoning_content and content.                             \n",
       "\n",
       "# 'thought_in_content': True,                                                                                      \n",
       "\n",
       "# },                                                                                                               \n",
       "\n",
       "}                                                                                                                  \n",
       "\n",
       "# Define Tools                                                                                                     \n",
       "\n",
       "tools = [                                                                                                          \n",
       "                                                                                                                   \n",
       "{'mcpServers': { # You can specify the MCP configuration file                                                      \n",
       "                                                                                                                   \n",
       "'time': {                                                                                                          \n",
       "                                                                                                                   \n",
       "'command': 'uvx',                                                                                                  \n",
       "                                                                                                                   \n",
       "'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']                                                      \n",
       "                                                                                                                   \n",
       "},                                                                                                                 \n",
       "                                                                                                                   \n",
       "\"fetch\": {                                                                                                         \n",
       "                                                                                                                   \n",
       "\"command\": \"uvx\",                                                                                                  \n",
       "                                                                                                                   \n",
       "\"args\": [\"mcp-server-fetch\"]                                                                                       \n",
       "                                                                                                                   \n",
       "}                                                                                                                  \n",
       "                                                                                                                   \n",
       "}                                                                                                                  \n",
       "                                                                                                                   \n",
       "},                                                                                                                 \n",
       "                                                                                                                   \n",
       "'code_interpreter', # Built-in tools                                                                               \n",
       "                                                                                                                   \n",
       "]                                                                                                                  \n",
       "\n",
       "# Define Agent                                                                                                     \n",
       "\n",
       "bot = Assistant(llm=llm_cfg, function_list=tools)                                                                  \n",
       "\n",
       "# Streaming generation                                                                                             \n",
       "\n",
       "messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of       \n",
       "Qwen'}]                                                                                                            \n",
       "\n",
       "for responses in bot.run(messages=messages):                                                                       \n",
       "\n",
       "pass                                                                                                               \n",
       "\n",
       "print(responses)                                                                                                   \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Friends of Qwen</span>                                                                                                    \n",
       "\n",
       "Thanks to the support of so many friends. Qwen is nothing without its friends! We welcome more people or           \n",
       "organizations to join our community and help us become better!                                                     \n",
       "\n",
       " <a href=\"https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-logo.png\" target=\"_blank\">qwen3-logo.png</a>                                                                                                                    \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; text-decoration: underline\">Future Work</span>                                                                                                        \n",
       "\n",
       "Qwen3 represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial\n",
       "Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher   \n",
       "levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the          \n",
       "flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages,  \n",
       "enhancing global accessibility.                                                                                    \n",
       "\n",
       "Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures \n",
       "and training methodologies to achieve several key objectives: scaling data, increasing model size, extending       \n",
       "context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We \n",
       "believe we are transitioning from an era focused on training models to one centered on training agents. Our next   \n",
       "iteration promises to bring meaningful advancements to everyone's work and life.                                   \n",
       "\n",
       "Try Qwen Chat                                                                                                      \n",
       "\n",
       "Web                                                                                                                \n",
       "\n",
       "iOS                                                                                                                \n",
       "\n",
       "Android                                                                                                            \n",
       "\n",
       "macOS                                                                                                              \n",
       "\n",
       "Windows                                                                                                            \n",
       "\n",
       "Qwen Chat                                                                                                          \n",
       "\n",
       "Qwen Chat Overview                                                                                                 \n",
       "\n",
       "Download                                                                                                           \n",
       "\n",
       "API Platform                                                                                                       \n",
       "\n",
       "Our Flagship Models                                                                                                \n",
       "\n",
       "Platform Overview                                                                                                  \n",
       "\n",
       "API Platform                                                                                                       \n",
       "\n",
       "Research                                                                                                           \n",
       "\n",
       "Latest Advancements                                                                                                \n",
       "\n",
       "Research Index                                                                                                     \n",
       "\n",
       "GitHub                                                                                                             \n",
       "\n",
       "Terms &amp; Policies                                                                                                   \n",
       "\n",
       "Terms of Service                                                                                                   \n",
       "\n",
       "Privacy Policy                                                                                                     \n",
       "\n",
       "Usage Policy                                                                                                       \n",
       "\n",
       " <a href=\"https://img.alicdn.com/imgextra/i2/O1CN01B9mlGG1msAz3fxxWL_!!6000000005009-2-tps-84-84.png\" target=\"_blank\">O1CN01B9mlGG1msAz3fxxWL_!!6000000005009-2-tps-84-84.png</a>  <a href=\"https://img.alicdn.com/imgextra/i3/O1CN01LF6pFa1PE79GHDehi_!!6000000001808-2-tps-72-72.png\" target=\"_blank\">O1CN01LF6pFa1PE79GHDehi_!!6000000001808-2-tps-72-72.png</a>  <a href=\"https://img.alicdn.com/imgextra/i3/O1CN01696apl1pyzhNJ40bg_!!6000000005430-2-tps-72-72.png\" target=\"_blank\">O1CN01696apl1pyzhNJ40bg_!!6000000005430-2-tps-72-72.png</a>  <a href=\"https://img.alicdn.com/imgextra/i2/O1CN01DJfj2R28G5Z6O677U_!!6000000007904-2-tps-72-72.png\" target=\"_blank\">O1CN01DJfj2R28G5Z6O677U_!!6000000007904-2-tps-72-72.png</a>  <a href=\"https://img.alicdn.com/imgextra/i2/O1CN01JbyKvo1NhlYiMFJ93_!!6000000001602-2-tps-72-72.png\" target=\"_blank\">O1CN01JbyKvo1NhlYiMFJ93_!!6000000001602-2-tps-72-72.png</a>  <a href=\"https://img.alicdn.com/imgextra/i2/O1CN01VmVMp41qYiaiS6nta_!!6000000005508-2-tps-72-72.png\" target=\"_blank\">O1CN01VmVMp41qYiaiS6nta_!!6000000005508-2-tps-72-72.png</a>  <a href=\"https://img.alicdn.com/imgextra/i4/O1CN01pQADTs1WKiABLBcVE_!!6000000002770-2-tps-72-72.png\" target=\"_blank\">O1CN01pQADTs1WKiABLBcVE_!!6000000002770-2-tps-72-72.png</a>                                                                                                                    \n",
       "\n",
       "Qwen  2026                                                                                                        \n",
       "\n",
       "Powered by Alibaba Cloud                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       " \u001b]8;id=129329;https://img.alicdn.com/imgextra/i4/O1CN01a6pmNi24dfWQwmMp3_!!6000000007414-2-tps-270-90.png\u001b\\logo\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "Qwen Chat                                                                                                          \n",
       "\n",
       "Research                                                                                                           \n",
       "\n",
       "API Platform                                                                                                       \n",
       "\n",
       "EN                                                                                                                 \n",
       "\n",
       "DownloadTry Qwen Chat                                                                                              \n",
       "\n",
       "Qwen3: Think Deeper, Act Faster                                                                                    \n",
       "\n",
       "2025/04/28  48 minute  9682 words  QwenTeamTranslations:                                              \n",
       "\n",
       " \u001b]8;id=369773;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-banner.png\u001b\\qwen3-banner.png\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "QWEN CHAT                                                                                                          \n",
       "\n",
       "GitHub                                                                                                             \n",
       "\n",
       "Hugging Face                                                                                                       \n",
       "\n",
       "ModelScope                                                                                                         \n",
       "\n",
       "Kaggle                                                                                                             \n",
       "\n",
       "DEMO                                                                                                               \n",
       "\n",
       "DISCORD                                                                                                            \n",
       "\n",
       "\u001b[4;35mIntroduction\u001b[0m                                                                                                       \n",
       "\n",
       "Today, we are excited to announce the release of \u001b[1mQwen3\u001b[0m, the latest addition to the Qwen family of large language   \n",
       "models. Our flagship model, \u001b[1mQwen3-235B-A22B\u001b[0m, achieves competitive results in benchmark evaluations of coding, math,\n",
       "general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and   \n",
       "Gemini-2.5-Pro. Additionally, the small MoE model, \u001b[1mQwen3-30B-A3B\u001b[0m, outcompetes QwQ-32B with 10 times of activated   \n",
       "parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.                 \n",
       "\n",
       " \u001b]8;id=866936;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-235a22.jpg\u001b\\qwen3-235a22.jpg\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       " \u001b]8;id=3985;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-30a3.jpg\u001b\\qwen3-30a3.jpg\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "We are open-weighting two MoE models: \u001b[1mQwen3-235B-A22B\u001b[0m, a large model with 235 billion total parameters and 22      \n",
       "billion activated parameters, and \u001b[1mQwen3-30B-A3B\u001b[0m, a smaller MoE model with 30 billion total parameters and 3 billion\n",
       "activated parameters. Additionally, six dense models are also open-weighted, including \u001b[1mQwen3-32B\u001b[0m, \u001b[1mQwen3-14B\u001b[0m,       \n",
       "\u001b[1mQwen3-8B\u001b[0m, \u001b[1mQwen3-4B\u001b[0m, \u001b[1mQwen3-1.7B\u001b[0m, and \u001b[1mQwen3-0.6B\u001b[0m, under Apache 2.0 license.                                          \n",
       "\n",
       "\u001b[36m                                                                   \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36mModels\u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mLayers\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mHeads (Q / KV)\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mTie Embedding\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mContext Length\u001b[0m\u001b[36m \u001b[0m\n",
       "\u001b[36m  \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-0.6B \u001b[36m \u001b[0m28     \u001b[36m \u001b[0m16 / 8         \u001b[36m \u001b[0mYes           \u001b[36m \u001b[0m32K           \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-1.7B \u001b[36m \u001b[0m28     \u001b[36m \u001b[0m16 / 8         \u001b[36m \u001b[0mYes           \u001b[36m \u001b[0m32K           \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-4B   \u001b[36m \u001b[0m36     \u001b[36m \u001b[0m32 / 8         \u001b[36m \u001b[0mYes           \u001b[36m \u001b[0m32K           \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-8B   \u001b[36m \u001b[0m36     \u001b[36m \u001b[0m32 / 8         \u001b[36m \u001b[0mNo            \u001b[36m \u001b[0m128K          \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-14B  \u001b[36m \u001b[0m40     \u001b[36m \u001b[0m40 / 8         \u001b[36m \u001b[0mNo            \u001b[36m \u001b[0m128K          \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-32B  \u001b[36m \u001b[0m64     \u001b[36m \u001b[0m64 / 8         \u001b[36m \u001b[0mNo            \u001b[36m \u001b[0m128K          \u001b[36m \u001b[0m\n",
       "\u001b[36m                                                                   \u001b[0m\n",
       "\n",
       "\u001b[36m                                                                                        \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36mModels\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mLayers\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mHeads (Q / KV)\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36m# Experts (Total / Activated)\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mContext Length\u001b[0m\u001b[36m \u001b[0m\n",
       "\u001b[36m  \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-30B-A3B   \u001b[36m \u001b[0m48     \u001b[36m \u001b[0m32 / 4         \u001b[36m \u001b[0m128 / 8                       \u001b[36m \u001b[0m128K          \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mQwen3-235B-A22B \u001b[36m \u001b[0m94     \u001b[36m \u001b[0m64 / 4         \u001b[36m \u001b[0m128 / 8                       \u001b[36m \u001b[0m128K          \u001b[36m \u001b[0m\n",
       "\u001b[36m                                                                                        \u001b[0m\n",
       "\n",
       "The post-trained models, such as \u001b[1mQwen3-30B-A3B\u001b[0m, along with their pre-trained counterparts (e.g.,                   \n",
       "\u001b[1mQwen3-30B-A3B-Base\u001b[0m), are now available on platforms like \u001b[1mHugging Face\u001b[0m, \u001b[1mModelScope\u001b[0m, and \u001b[1mKaggle\u001b[0m. For deployment, we  \n",
       "recommend using frameworks like \u001b[1mSGLang\u001b[0m and \u001b[1mvLLM\u001b[0m. For local usage, tools such as \u001b[1mOllama\u001b[0m, \u001b[1mLMStudio\u001b[0m, \u001b[1mMLX\u001b[0m, \u001b[1mllama.cpp\u001b[0m,  \n",
       "and \u001b[1mKTransformers\u001b[0m are highly recommended. These options ensure that users can easily integrate Qwen3 into their    \n",
       "workflows, whether in research, development, or production environments.                                           \n",
       "\n",
       "We believe that the release and open-sourcing of Qwen3 will significantly advance the research and development of  \n",
       "large foundation models. Our goal is to empower researchers, developers, and organizations around the world to     \n",
       "build innovative solutions using these cutting-edge models.                                                        \n",
       "\n",
       "Feel free to try Qwen3 out in Qwen Chat Web ( \u001b]8;id=292745;https://chat.qwen.ai/\u001b\\\u001b[4;34mchat.qwen.ai\u001b[0m\u001b]8;;\u001b\\) and mobile APP!                                        \n",
       "\n",
       "\u001b[4;35mKey Features\u001b[0m                                                                                                       \n",
       "\n",
       "\u001b[1mHybrid Thinking Modes\u001b[0m                                                                                              \n",
       "\n",
       "Qwen3 models introduce a hybrid approach to problem-solving. They support two modes:                               \n",
       "\n",
       "Thinking Mode: In this mode, the model takes time to reason step by step before delivering the final answer. This  \n",
       "is ideal for complex problems that require deeper thought.                                                         \n",
       "\n",
       "Non-Thinking Mode: Here, the model provides quick, near-instant responses, suitable for simpler questions where    \n",
       "speed is more important than depth.                                                                                \n",
       "\n",
       "This flexibility allows users to control how much \"thinking\" the model performs based on the task at hand. For     \n",
       "example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without\n",
       "delay. Crucially, the integration of these two modes greatly enhances the model's ability to implement stable and  \n",
       "efficient thinking budget control. As demonstrated above, Qwen3 exhibits scalable and smooth performance           \n",
       "improvements that are directly correlated with the computational reasoning budget allocated. This design enables   \n",
       "users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost          \n",
       "efficiency and inference quality.                                                                                  \n",
       "\n",
       " \u001b]8;id=663916;https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/thinking_budget.png\u001b\\thinking_budget.png\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "\u001b[1mMultilingual Support\u001b[0m                                                                                               \n",
       "\n",
       "Qwen3 models are supporting \u001b[1m119 languages and dialects\u001b[0m. This extensive multilingual capability opens up new        \n",
       "possibilities for international applications, enabling users worldwide to benefit from the power of these models.  \n",
       "\n",
       "\u001b[36m                                                                                                                   \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36mLanguage Family\u001b[0m\u001b[1m \u001b[0m\u001b[36m \u001b[0m\u001b[36mLanguages & Dialects\u001b[0m\u001b[1m                                                                            \u001b[0m\u001b[36m \u001b[0m\n",
       "\u001b[36m  \u001b[0m\n",
       "\u001b[36m \u001b[0mIndo-European   \u001b[36m \u001b[0mEnglish, French, Portuguese, German, Romanian, Swedish, Danish, Bulgarian, Russian, Czech,      \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mGreek, Ukrainian, Spanish, Dutch, Slovak, Croatian, Polish, Lithuanian, Norwegian Bokml,       \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mNorwegian Nynorsk, Persian, Slovenian, Gujarati, Latvian, Italian, Occitan, Nepali, Marathi,    \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mBelarusian, Serbian, Luxembourgish, Venetian, Assamese, Welsh, Silesian, Asturian,              \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mChhattisgarhi, Awadhi, Maithili, Bhojpuri, Sindhi, Irish, Faroese, Hindi, Punjabi, Bengali,     \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mOriya, Tajik, Eastern Yiddish, Lombard, Ligurian, Sicilian, Friulian, Sardinian, Galician,      \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mCatalan, Icelandic, Tosk Albanian, Limburgish, Dari, Afrikaans, Macedonian, Sinhala, Urdu,      \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mMagahi, Bosnian, Armenian                                                                       \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mSino-Tibetan    \u001b[36m \u001b[0mChinese (Simplified Chinese, Traditional Chinese, Cantonese), Burmese                           \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mAfro-Asiatic    \u001b[36m \u001b[0mArabic (Standard, Najdi, Levantine, Egyptian, Moroccan, Mesopotamian, Ta'izzi-Adeni, Tunisian), \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mHebrew, Maltese                                                                                 \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mAustronesian    \u001b[36m \u001b[0mIndonesian, Malay, Tagalog, Cebuano, Javanese, Sundanese, Minangkabau, Balinese, Banjar,        \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0m                \u001b[36m \u001b[0mPangasinan, Iloko, Waray (Philippines)                                                          \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mDravidian       \u001b[36m \u001b[0mTamil, Telugu, Kannada, Malayalam                                                               \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mTurkic          \u001b[36m \u001b[0mTurkish, North Azerbaijani, Northern Uzbek, Kazakh, Bashkir, Tatar                              \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mTai-Kadai       \u001b[36m \u001b[0mThai, Lao                                                                                       \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mUralic          \u001b[36m \u001b[0mFinnish, Estonian, Hungarian                                                                    \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mAustroasiatic   \u001b[36m \u001b[0mVietnamese, Khmer                                                                               \u001b[36m \u001b[0m\n",
       "\u001b[36m \u001b[0mOther           \u001b[36m \u001b[0mJapanese, Korean, Georgian, Basque, Haitian, Papiamento, Kabuverdianu, Tok Pisin, Swahili       \u001b[36m \u001b[0m\n",
       "\u001b[36m                                                                                                                   \u001b[0m\n",
       "\n",
       "\u001b[1mImproved Agentic Capabilities\u001b[0m                                                                                      \n",
       "\n",
       "We have optimized the Qwen3 models for coding and agentic capabilities, and also we have strengthened the support  \n",
       "of MCP as well. Below we provide examples to show how Qwen3 thinks and interacts with the environment.             \n",
       "\n",
       "\u001b[4;35mPre-training\u001b[0m                                                                                                       \n",
       "\n",
       "In terms of pretraining, the dataset for Qwen3 has been significantly expanded compared to Qwen2.5. While Qwen2.5  \n",
       "was pre-trained on 18 trillion tokens, Qwen3 uses nearly twice that amount, with approximately 36 trillion tokens  \n",
       "covering 119 languages and dialects. To build this large dataset, we collected data not only from the web but also \n",
       "from PDF-like documents. We used Qwen2.5-VL to extract text from these documents and Qwen2.5 to improve the quality\n",
       "of the extracted content. To increase the amount of math and code data, we used Qwen2.5-Math and Qwen2.5-Coder to  \n",
       "generate synthetic data. This includes textbooks, question-answer pairs, and code snippets.                        \n",
       "\n",
       "The pre-training process consists of three stages. In the first stage (S1), the model was pretrained on over 30    \n",
       "trillion tokens with a context length of 4K tokens. This stage provided the model with basic language skills and   \n",
       "general knowledge. In the second stage (S2), we improved the dataset by increasing the proportion of               \n",
       "knowledge-intensive data, such as STEM, coding, and reasoning tasks. The model was then pretrained on an additional\n",
       "5 trillion tokens. In the final stage, we used high-quality long-context data to extend the context length to 32K  \n",
       "tokens. This ensures the model can handle longer inputs effectively.                                               \n",
       "\n",
       " \u001b]8;id=43717;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-base.jpg\u001b\\qwen3-base.jpg\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "Due to advancements in model architecture, increase in training data, and more effective training methods, the     \n",
       "overall performance of Qwen3 dense base models matches that of Qwen2.5 base models with more parameters. For       \n",
       "instance, Qwen3-1.7B/4B/8B/14B/32B-Base performs as well as Qwen2.5-3B/7B/14B/32B/72B-Base, respectively. Notably, \n",
       "in areas like STEM, coding, and reasoning, Qwen3 dense base models even outperform larger Qwen2.5 models. For      \n",
       "Qwen3-MoE base models, they achieve similar performance to Qwen2.5 dense base models while using only 10% of the   \n",
       "active parameters. This results in significant savings in both training and inference costs.                       \n",
       "\n",
       "\u001b[4;35mPost-training\u001b[0m                                                                                                      \n",
       "\n",
       " \u001b]8;id=327298;https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/post-training.png\u001b\\post-training.png\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "To develop the hybrid model capable of both step-by-step reasoning and rapid responses, we implemented a four-stage\n",
       "training pipeline. This pipeline includes: (1) long chain-of-thought (CoT) cold start, (2) reasoning-based         \n",
       "reinforcement learning (RL), (3) thinking mode fusion, and (4) general RL.                                         \n",
       "\n",
       "In the first stage, we fine-tuned the models using diverse long CoT data, covering various tasks and domains such  \n",
       "as mathematics, coding, logical reasoning, and STEM problems. This process aimed to equip the model with           \n",
       "fundamental reasoning abilities. The second stage focused on scaling up computational resources for RL, utilizing  \n",
       "rule-based rewards to enhance the model's exploration and exploitation capabilities.                               \n",
       "\n",
       "In the third stage, we integrated non-thinking capabilities into the thinking model by fine-tuning it on a         \n",
       "combination of long CoT data and commonly used instruction-tuning data. This data was generated by the enhanced    \n",
       "thinking model from the second stage, ensuring a seamless blend of reasoning and quick response capabilities.      \n",
       "Finally, in the fourth stage, we applied RL across more than 20 general-domain tasks to further strengthen the     \n",
       "models general capabilities and correct undesired behaviors. These tasks included instruction following, format   \n",
       "following, and agent capabilities, etc.                                                                            \n",
       "\n",
       "\u001b[4;35mDevelop with Qwen3\u001b[0m                                                                                                 \n",
       "\n",
       "Below is a simple guide for you to use Qwen3 on different frameworks. First of all, we provide an standard example \n",
       "of using Qwen3-30B-A3B in Hugging Face transformers:                                                               \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "99                                                                                                                 \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "7                                                                                                                  \n",
       "\n",
       "8                                                                                                                  \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "10                                                                                                                 \n",
       "\n",
       "11                                                                                                                 \n",
       "\n",
       "12                                                                                                                 \n",
       "\n",
       "13                                                                                                                 \n",
       "\n",
       "14                                                                                                                 \n",
       "\n",
       "15                                                                                                                 \n",
       "\n",
       "16                                                                                                                 \n",
       "\n",
       "17                                                                                                                 \n",
       "\n",
       "18                                                                                                                 \n",
       "\n",
       "19                                                                                                                 \n",
       "\n",
       "20                                                                                                                 \n",
       "\n",
       "21                                                                                                                 \n",
       "\n",
       "22                                                                                                                 \n",
       "\n",
       "23                                                                                                                 \n",
       "\n",
       "24                                                                                                                 \n",
       "\n",
       "25                                                                                                                 \n",
       "\n",
       "26                                                                                                                 \n",
       "\n",
       "27                                                                                                                 \n",
       "\n",
       "28                                                                                                                 \n",
       "\n",
       "29                                                                                                                 \n",
       "\n",
       "30                                                                                                                 \n",
       "\n",
       "31                                                                                                                 \n",
       "\n",
       "32                                                                                                                 \n",
       "\n",
       "33                                                                                                                 \n",
       "\n",
       "34                                                                                                                 \n",
       "\n",
       "35                                                                                                                 \n",
       "\n",
       "36                                                                                                                 \n",
       "\n",
       "37                                                                                                                 \n",
       "\n",
       "38                                                                                                                 \n",
       "\n",
       "39                                                                                                                 \n",
       "\n",
       "40                                                                                                                 \n",
       "\n",
       "41                                                                                                                 \n",
       "\n",
       "42                                                                                                                 \n",
       "\n",
       "43                                                                                                                 \n",
       "\n",
       "44                                                                                                                 \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "from modelscope import AutoModelForCausalLM, AutoTokenizer                                                         \n",
       "\n",
       "model_name = \"Qwen/Qwen3-30B-A3B\"                                                                                  \n",
       "\n",
       "# load the tokenizer and the model                                                                                 \n",
       "\n",
       "tokenizer = AutoTokenizer.from_pretrained(model_name)                                                              \n",
       "\n",
       "model = AutoModelForCausalLM.from_pretrained(                                                                      \n",
       "\n",
       "model_name,                                                                                                        \n",
       "\n",
       "torch_dtype=\"auto\",                                                                                                \n",
       "\n",
       "device_map=\"auto\"                                                                                                  \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "# prepare the model input                                                                                          \n",
       "\n",
       "prompt = \"Give me a short introduction to large language model.\"                                                   \n",
       "\n",
       "messages = [                                                                                                       \n",
       "                                                                                                                   \n",
       "{\"role\": \"user\", \"content\": prompt}                                                                                \n",
       "                                                                                                                   \n",
       "]                                                                                                                  \n",
       "\n",
       "text = tokenizer.apply_chat_template(                                                                              \n",
       "\n",
       "messages,                                                                                                          \n",
       "\n",
       "tokenize=False,                                                                                                    \n",
       "\n",
       "add_generation_prompt=True,                                                                                        \n",
       "\n",
       "enable_thinking=True# Switch between thinking and non-thinking modes. Default is True.                             \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)                                             \n",
       "\n",
       "# conduct text completion                                                                                          \n",
       "\n",
       "generated_ids = model.generate(                                                                                    \n",
       "\n",
       "**model_inputs,                                                                                                    \n",
       "\n",
       "max_new_tokens=32768                                                                                               \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()                                            \n",
       "\n",
       "# parsing thinking content                                                                                         \n",
       "\n",
       "try:                                                                                                               \n",
       "\n",
       "\n",
       "# rindex finding 151668 ()                                                                                         \n",
       "\n",
       "index = len(output_ids) - output_ids[::-1].index(151668)                                                           \n",
       "\n",
       "except ValueError:                                                                                                 \n",
       "\n",
       "index = 0                                                                                                          \n",
       "\n",
       "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")                      \n",
       "\n",
       "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")                               \n",
       "\n",
       "print(\"thinking content:\", thinking_content)                                                                       \n",
       "\n",
       "print(\"content:\", content)                                                                                         \n",
       "\n",
       "To disable thinking, you just need to make changes to the argument \u001b[1;36;40menable_thinking\u001b[0m like the following:             \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "text = tokenizer.apply_chat_template(                                                                              \n",
       "\n",
       "messages,                                                                                                          \n",
       "\n",
       "tokenize=False,                                                                                                    \n",
       "\n",
       "add_generation_prompt=True,                                                                                        \n",
       "\n",
       "enable_thinking=False# True is the default value for enable_thinking.                                              \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "For deployment, you can use \u001b[1;36;40msglang>=0.4.6.post1\u001b[0m or \u001b[1;36;40mvllm>=0.8.4\u001b[0m to create an OpenAI-compatible API endpoint:        \n",
       "\n",
       "SGLang:                                                                                                            \n",
       "\n",
       "shell                                                                                                              \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3                            \n",
       "\n",
       "vLLM:                                                                                                              \n",
       "\n",
       "shell                                                                                                              \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1                                    \n",
       "\n",
       "If you use it for local development, you can use ollama by running a simple command \u001b[1;36;40mollama run qwen3:30b-a3b\u001b[0m to    \n",
       "play with the model, or you can use LMStudio or llama.cpp and ktransformers to build locally.                      \n",
       "\n",
       "\u001b[1;35mAdvanced Usages\u001b[0m                                                                                                    \n",
       "\n",
       "We provide a soft switch mechanism that allows users to dynamically control the model's behavior when              \n",
       "enable_thinking=True. Specifically, you can add /think and /no_think to user prompts or system messages to switch  \n",
       "the model's thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn       \n",
       "conversations.                                                                                                     \n",
       "\n",
       "Here is an example of a multi-turn conversation:                                                                   \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "99                                                                                                                 \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "7                                                                                                                  \n",
       "\n",
       "8                                                                                                                  \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "10                                                                                                                 \n",
       "\n",
       "11                                                                                                                 \n",
       "\n",
       "12                                                                                                                 \n",
       "\n",
       "13                                                                                                                 \n",
       "\n",
       "14                                                                                                                 \n",
       "\n",
       "15                                                                                                                 \n",
       "\n",
       "16                                                                                                                 \n",
       "\n",
       "17                                                                                                                 \n",
       "\n",
       "18                                                                                                                 \n",
       "\n",
       "19                                                                                                                 \n",
       "\n",
       "20                                                                                                                 \n",
       "\n",
       "21                                                                                                                 \n",
       "\n",
       "22                                                                                                                 \n",
       "\n",
       "23                                                                                                                 \n",
       "\n",
       "24                                                                                                                 \n",
       "\n",
       "25                                                                                                                 \n",
       "\n",
       "26                                                                                                                 \n",
       "\n",
       "27                                                                                                                 \n",
       "\n",
       "28                                                                                                                 \n",
       "\n",
       "29                                                                                                                 \n",
       "\n",
       "30                                                                                                                 \n",
       "\n",
       "31                                                                                                                 \n",
       "\n",
       "32                                                                                                                 \n",
       "\n",
       "33                                                                                                                 \n",
       "\n",
       "34                                                                                                                 \n",
       "\n",
       "35                                                                                                                 \n",
       "\n",
       "36                                                                                                                 \n",
       "\n",
       "37                                                                                                                 \n",
       "\n",
       "38                                                                                                                 \n",
       "\n",
       "39                                                                                                                 \n",
       "\n",
       "40                                                                                                                 \n",
       "\n",
       "41                                                                                                                 \n",
       "\n",
       "42                                                                                                                 \n",
       "\n",
       "43                                                                                                                 \n",
       "\n",
       "44                                                                                                                 \n",
       "\n",
       "45                                                                                                                 \n",
       "\n",
       "46                                                                                                                 \n",
       "\n",
       "47                                                                                                                 \n",
       "\n",
       "48                                                                                                                 \n",
       "\n",
       "49                                                                                                                 \n",
       "\n",
       "50                                                                                                                 \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "from transformers import AutoModelForCausalLM, AutoTokenizer                                                       \n",
       "\n",
       "classQwenChatbot:                                                                                                  \n",
       "\n",
       "def__init__(self, model_name=\"Qwen/Qwen3-30B-A3B\"):                                                                \n",
       "\n",
       "self.tokenizer = AutoTokenizer.from_pretrained(model_name)                                                         \n",
       "\n",
       "self.model = AutoModelForCausalLM.from_pretrained(model_name)                                                      \n",
       "\n",
       "self.history = []                                                                                                  \n",
       "\n",
       "defgenerate_response(self, user_input):                                                                            \n",
       "\n",
       "messages = self.history + [{\"role\": \"user\", \"content\": user_input}]                                                \n",
       "\n",
       "text = self.tokenizer.apply_chat_template(                                                                         \n",
       "\n",
       "messages,                                                                                                          \n",
       "\n",
       "tokenize=False,                                                                                                    \n",
       "\n",
       "add_generation_prompt=True                                                                                         \n",
       "\n",
       ")                                                                                                                  \n",
       "\n",
       "inputs = self.tokenizer(text, return_tensors=\"pt\")                                                                 \n",
       "\n",
       "response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()          \n",
       "\n",
       "response = self.tokenizer.decode(response_ids, skip_special_tokens=True)                                           \n",
       "\n",
       "# Update history                                                                                                   \n",
       "\n",
       "self.history.append({\"role\": \"user\", \"content\": user_input})                                                       \n",
       "\n",
       "self.history.append({\"role\": \"assistant\", \"content\": response})                                                    \n",
       "\n",
       "return response                                                                                                    \n",
       "\n",
       "# Example Usage                                                                                                    \n",
       "\n",
       "if __name__ == \"__main__\":                                                                                         \n",
       "\n",
       "chatbot = QwenChatbot()                                                                                            \n",
       "\n",
       "# First input (without /think or /no_think tags, thinking mode is enabled by default)                              \n",
       "\n",
       "user_input_1 = \"How many r's in strawberries?\"                                                                     \n",
       "\n",
       "print(f\"User: {user_input_1}\")                                                                                     \n",
       "\n",
       "response_1 = chatbot.generate_response(user_input_1)                                                               \n",
       "\n",
       "print(f\"Bot: {response_1}\")                                                                                        \n",
       "\n",
       "print(\"----------------------\")                                                                                    \n",
       "\n",
       "# Second input with /no_think                                                                                      \n",
       "\n",
       "user_input_2 = \"Then, how many r's in blueberries? /no_think\"                                                      \n",
       "\n",
       "print(f\"User: {user_input_2}\")                                                                                     \n",
       "\n",
       "response_2 = chatbot.generate_response(user_input_2)                                                               \n",
       "\n",
       "print(f\"Bot: {response_2}\")                                                                                        \n",
       "\n",
       "print(\"----------------------\")                                                                                    \n",
       "\n",
       "# Third input with /think                                                                                          \n",
       "\n",
       "user_input_3 = \"Really? /think\"                                                                                    \n",
       "\n",
       "print(f\"User: {user_input_3}\")                                                                                     \n",
       "\n",
       "response_3 = chatbot.generate_response(user_input_3)                                                               \n",
       "\n",
       "print(f\"Bot: {response_3}\")                                                                                        \n",
       "\n",
       "\u001b[1;35mAgentic Usages\u001b[0m                                                                                                     \n",
       "\n",
       "Qwen3 excels in tool calling capabilities. We recommend using \u001b]8;id=524827;https://github.com/QwenLM/Qwen-Agent\u001b\\\u001b[4;34mQwen-Agent\u001b[0m\u001b]8;;\u001b\\ to make the best use of agentic ability of\n",
       "Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding \n",
       "complexity.                                                                                                        \n",
       "\n",
       "To define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or   \n",
       "integrate other tools by yourself.                                                                                 \n",
       "\n",
       "python                                                                                                             \n",
       "\n",
       "99                                                                                                                 \n",
       "\n",
       "1                                                                                                                  \n",
       "\n",
       "2                                                                                                                  \n",
       "\n",
       "3                                                                                                                  \n",
       "\n",
       "4                                                                                                                  \n",
       "\n",
       "5                                                                                                                  \n",
       "\n",
       "6                                                                                                                  \n",
       "\n",
       "7                                                                                                                  \n",
       "\n",
       "8                                                                                                                  \n",
       "\n",
       "9                                                                                                                  \n",
       "\n",
       "10                                                                                                                 \n",
       "\n",
       "11                                                                                                                 \n",
       "\n",
       "12                                                                                                                 \n",
       "\n",
       "13                                                                                                                 \n",
       "\n",
       "14                                                                                                                 \n",
       "\n",
       "15                                                                                                                 \n",
       "\n",
       "16                                                                                                                 \n",
       "\n",
       "17                                                                                                                 \n",
       "\n",
       "18                                                                                                                 \n",
       "\n",
       "19                                                                                                                 \n",
       "\n",
       "20                                                                                                                 \n",
       "\n",
       "21                                                                                                                 \n",
       "\n",
       "22                                                                                                                 \n",
       "\n",
       "23                                                                                                                 \n",
       "\n",
       "24                                                                                                                 \n",
       "\n",
       "25                                                                                                                 \n",
       "\n",
       "26                                                                                                                 \n",
       "\n",
       "27                                                                                                                 \n",
       "\n",
       "28                                                                                                                 \n",
       "\n",
       "29                                                                                                                 \n",
       "\n",
       "30                                                                                                                 \n",
       "\n",
       "31                                                                                                                 \n",
       "\n",
       "32                                                                                                                 \n",
       "\n",
       "33                                                                                                                 \n",
       "\n",
       "34                                                                                                                 \n",
       "\n",
       "35                                                                                                                 \n",
       "\n",
       "36                                                                                                                 \n",
       "\n",
       "37                                                                                                                 \n",
       "\n",
       "38                                                                                                                 \n",
       "\n",
       "39                                                                                                                 \n",
       "\n",
       "40                                                                                                                 \n",
       "\n",
       "41                                                                                                                 \n",
       "\n",
       "42                                                                                                                 \n",
       "\n",
       "43                                                                                                                 \n",
       "\n",
       "44                                                                                                                 \n",
       "\n",
       "45                                                                                                                 \n",
       "\n",
       "46                                                                                                                 \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "                                                                                                                  \n",
       "\n",
       "from qwen_agent.agents import Assistant                                                                            \n",
       "\n",
       "# Define LLM                                                                                                       \n",
       "\n",
       "llm_cfg = {                                                                                                        \n",
       "\n",
       "'model': 'Qwen3-30B-A3B',                                                                                          \n",
       "\n",
       "# Use the endpoint provided by Alibaba Model Studio:                                                               \n",
       "\n",
       "# 'model_type': 'qwen_dashscope',                                                                                  \n",
       "\n",
       "# 'api_key': os.getenv('DASHSCOPE_API_KEY'),                                                                       \n",
       "\n",
       "# Use a custom endpoint compatible with OpenAI API:                                                                \n",
       "\n",
       "'model_server': 'http://localhost:8000/v1', # api_base                                                             \n",
       "\n",
       "'api_key': 'EMPTY',                                                                                                \n",
       "\n",
       "# Other parameters:                                                                                                \n",
       "\n",
       "# 'generate_cfg': {                                                                                                \n",
       "\n",
       "\n",
       "\n",
       "# # Add: When the response content is `this is the thoughtthis is the answer;                                      \n",
       "\n",
       "# # Do not add: When the response has been separated by reasoning_content and content.                             \n",
       "\n",
       "# 'thought_in_content': True,                                                                                      \n",
       "\n",
       "# },                                                                                                               \n",
       "\n",
       "}                                                                                                                  \n",
       "\n",
       "# Define Tools                                                                                                     \n",
       "\n",
       "tools = [                                                                                                          \n",
       "                                                                                                                   \n",
       "{'mcpServers': { # You can specify the MCP configuration file                                                      \n",
       "                                                                                                                   \n",
       "'time': {                                                                                                          \n",
       "                                                                                                                   \n",
       "'command': 'uvx',                                                                                                  \n",
       "                                                                                                                   \n",
       "'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']                                                      \n",
       "                                                                                                                   \n",
       "},                                                                                                                 \n",
       "                                                                                                                   \n",
       "\"fetch\": {                                                                                                         \n",
       "                                                                                                                   \n",
       "\"command\": \"uvx\",                                                                                                  \n",
       "                                                                                                                   \n",
       "\"args\": [\"mcp-server-fetch\"]                                                                                       \n",
       "                                                                                                                   \n",
       "}                                                                                                                  \n",
       "                                                                                                                   \n",
       "}                                                                                                                  \n",
       "                                                                                                                   \n",
       "},                                                                                                                 \n",
       "                                                                                                                   \n",
       "'code_interpreter', # Built-in tools                                                                               \n",
       "                                                                                                                   \n",
       "]                                                                                                                  \n",
       "\n",
       "# Define Agent                                                                                                     \n",
       "\n",
       "bot = Assistant(llm=llm_cfg, function_list=tools)                                                                  \n",
       "\n",
       "# Streaming generation                                                                                             \n",
       "\n",
       "messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of       \n",
       "Qwen'}]                                                                                                            \n",
       "\n",
       "for responses in bot.run(messages=messages):                                                                       \n",
       "\n",
       "pass                                                                                                               \n",
       "\n",
       "print(responses)                                                                                                   \n",
       "\n",
       "\u001b[4;35mFriends of Qwen\u001b[0m                                                                                                    \n",
       "\n",
       "Thanks to the support of so many friends. Qwen is nothing without its friends! We welcome more people or           \n",
       "organizations to join our community and help us become better!                                                     \n",
       "\n",
       " \u001b]8;id=157360;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-logo.png\u001b\\qwen3-logo.png\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "\u001b[4;35mFuture Work\u001b[0m                                                                                                        \n",
       "\n",
       "Qwen3 represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial\n",
       "Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher   \n",
       "levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the          \n",
       "flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages,  \n",
       "enhancing global accessibility.                                                                                    \n",
       "\n",
       "Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures \n",
       "and training methodologies to achieve several key objectives: scaling data, increasing model size, extending       \n",
       "context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We \n",
       "believe we are transitioning from an era focused on training models to one centered on training agents. Our next   \n",
       "iteration promises to bring meaningful advancements to everyone's work and life.                                   \n",
       "\n",
       "Try Qwen Chat                                                                                                      \n",
       "\n",
       "Web                                                                                                                \n",
       "\n",
       "iOS                                                                                                                \n",
       "\n",
       "Android                                                                                                            \n",
       "\n",
       "macOS                                                                                                              \n",
       "\n",
       "Windows                                                                                                            \n",
       "\n",
       "Qwen Chat                                                                                                          \n",
       "\n",
       "Qwen Chat Overview                                                                                                 \n",
       "\n",
       "Download                                                                                                           \n",
       "\n",
       "API Platform                                                                                                       \n",
       "\n",
       "Our Flagship Models                                                                                                \n",
       "\n",
       "Platform Overview                                                                                                  \n",
       "\n",
       "API Platform                                                                                                       \n",
       "\n",
       "Research                                                                                                           \n",
       "\n",
       "Latest Advancements                                                                                                \n",
       "\n",
       "Research Index                                                                                                     \n",
       "\n",
       "GitHub                                                                                                             \n",
       "\n",
       "Terms & Policies                                                                                                   \n",
       "\n",
       "Terms of Service                                                                                                   \n",
       "\n",
       "Privacy Policy                                                                                                     \n",
       "\n",
       "Usage Policy                                                                                                       \n",
       "\n",
       " \u001b]8;id=100754;https://img.alicdn.com/imgextra/i2/O1CN01B9mlGG1msAz3fxxWL_!!6000000005009-2-tps-84-84.png\u001b\\O1CN01B9mlGG1msAz3fxxWL_!!6000000005009-2-tps-84-84.png\u001b]8;;\u001b\\  \u001b]8;id=312330;https://img.alicdn.com/imgextra/i3/O1CN01LF6pFa1PE79GHDehi_!!6000000001808-2-tps-72-72.png\u001b\\O1CN01LF6pFa1PE79GHDehi_!!6000000001808-2-tps-72-72.png\u001b]8;;\u001b\\  \u001b]8;id=473846;https://img.alicdn.com/imgextra/i3/O1CN01696apl1pyzhNJ40bg_!!6000000005430-2-tps-72-72.png\u001b\\O1CN01696apl1pyzhNJ40bg_!!6000000005430-2-tps-72-72.png\u001b]8;;\u001b\\  \u001b]8;id=392677;https://img.alicdn.com/imgextra/i2/O1CN01DJfj2R28G5Z6O677U_!!6000000007904-2-tps-72-72.png\u001b\\O1CN01DJfj2R28G5Z6O677U_!!6000000007904-2-tps-72-72.png\u001b]8;;\u001b\\  \u001b]8;id=88347;https://img.alicdn.com/imgextra/i2/O1CN01JbyKvo1NhlYiMFJ93_!!6000000001602-2-tps-72-72.png\u001b\\O1CN01JbyKvo1NhlYiMFJ93_!!6000000001602-2-tps-72-72.png\u001b]8;;\u001b\\  \u001b]8;id=359827;https://img.alicdn.com/imgextra/i2/O1CN01VmVMp41qYiaiS6nta_!!6000000005508-2-tps-72-72.png\u001b\\O1CN01VmVMp41qYiaiS6nta_!!6000000005508-2-tps-72-72.png\u001b]8;;\u001b\\  \u001b]8;id=731303;https://img.alicdn.com/imgextra/i4/O1CN01pQADTs1WKiABLBcVE_!!6000000002770-2-tps-72-72.png\u001b\\O1CN01pQADTs1WKiABLBcVE_!!6000000002770-2-tps-72-72.png\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "Qwen  2026                                                                                                        \n",
       "\n",
       "Powered by Alibaba Cloud                                                                                           \n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Markdown(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8adda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production-agents (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
