{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4953d4",
   "metadata": {},
   "source": [
    "### Need a Harry Potter Chat\n",
    "- I ask ask any query related to harry potter\n",
    "-  Out of box question :  respond no\n",
    "-  RAG + Agent\n",
    "-  Prerequsite:\n",
    "   -  Harry Potter - full text data \n",
    "   -  RAG - Database : `PineCone` \n",
    "   -  Embedding Model :Opneai\n",
    "   -  Tracing, Evaluation, Deployment\n",
    "   -   Tracing, to mponiter, the step by step invocatioon and llm call of an agent\n",
    "   -   Evaluation :  How well you agent is perfoming\n",
    "   -   Deployment : Everyone can use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bb418",
   "metadata": {},
   "source": [
    "## Things need to check\n",
    " - Embeddding model context length -- how it works\n",
    " - Loading / Cleaning\n",
    " - Clean - Cutting\n",
    " -  Evaluate RAG\n",
    " -      Perfomce = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d140cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data loading\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(file_path=\"./harry.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "317fc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_load = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1848c4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3623"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6c3b1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "## gpt-5-mini = 400k , 40k(10%)\n",
    "## pdf : 800 - 1200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a401e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = splitter.split_documents(normal_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "387db224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8887"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43912109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Embedding\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import tiktoken\n",
    "\n",
    "# Price: About $0.13 per 1M tokens\n",
    "text = \"Harry potter is a cursed child\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
    "\n",
    "len(encoding.encode(text))\n",
    "len(encoding.encode(normal_load[5].page_content))\n",
    "sum([len(encoding.encode(page.page_content)) for page in normal_load])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "88c4be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_db  =  Chroma(\n",
    "    collection_name=\"harry_collection\",\n",
    "    embedding_function=embedding,\n",
    "    chroma_cloud_api_key=os.getenv(\"CHROMA_API_KEY\"),\n",
    "    tenant=os.getenv(\"CHROMA_TENANT\"),\n",
    "    database=os.getenv(\"CHROMA_DATABASE\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0808c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(docs),300):\n",
    "    vector_db.add_documents(documents=docs[i:i+300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f8d8071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8887"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2810d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ContextualCompressionRetriever' from 'langchain_core.retrievers' (/Users/sachin/Desktop/Production_Agents/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[205]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContextualCompressionRetriever\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from langchain.retrievers.document_compressors import FlashrankRerank\u001b[39;00m\n\u001b[32m      4\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mIn the harry potter series, who is refferred as Half Blood Prince?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ContextualCompressionRetriever' from 'langchain_core.retrievers' (/Users/sachin/Desktop/Production_Agents/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"In the harry potter series, who is refferred as Half Blood Prince?\"\n",
    "\n",
    "out = vector_db.similarity_search_with_relevance_scores(prompt, k=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e7d1640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my particular brand of reasoned argument is making much headway against\n",
      "Greyback’s insistence that we werewolves deserve blood, that we ought to\n",
      "revenge ourselves on normal people.”\n",
      "“But you are normal!” said Harry fiercely. “You’ve just got a — a problem\n",
      "—”\n",
      "Lupin burst out laughing. “Sometimes you remind me a lot of James. He\n",
      "called it my ‘furry little problem’ in company. Many people were under the\n",
      "impression that I owned a badly behaved rabbit.”\n",
      "He accepted a glass of eggnog from Mr. Weasley with a word of thanks,\n",
      "looking slightly more cheerful. Harry, meanwhile, felt a rush of excitement:\n",
      "This last mention of his father had reminded him that there was something he\n",
      "had been looking forward to asking Lupin.\n",
      "“Have you ever heard of someone called the Half-Blood Prince?”\n",
      "“The Half-Blood what?”\n",
      "“Prince,” said Harry, watching him closely for signs of recognition.\n",
      "“There are no Wizarding princes,” said Lupin, now smiling. “Is this a title\n"
     ]
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "\n",
    "\n",
    "print(out[1][0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c7021da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5651803826798749\n",
      "0.4054069891756842\n",
      "0.38145982808130807\n",
      "0.3799342169166269\n",
      "0.3464362352394422\n",
      "0.3353686281845816\n",
      "0.3300283032146195\n",
      "0.30439876538217314\n",
      "0.30007639133440733\n",
      "0.29955010589930575\n",
      "0.28539173510387883\n",
      "0.279558174869768\n",
      "0.2777522948612955\n",
      "0.2658031094980584\n",
      "0.26483345396901736\n",
      "0.2609636706876177\n",
      "0.2574429860240899\n",
      "0.25082835563948036\n",
      "0.25014741180919775\n",
      "0.24106285743790357\n"
     ]
    }
   ],
   "source": [
    "for score in out:\n",
    "    print(score[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ccf82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production-agents (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
